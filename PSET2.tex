%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Do not alter this block of commands.  If you're proficient at LaTeX, you may include additional packages, create macros, etc. immediately below this block of commands, but make sure to NOT alter the header, margin, and comment settings here. 
\documentclass[12pt]{article}
 \usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts, enumitem, fancyhdr, color, comment, graphicx, environ}
\usepackage{float}
\usepackage[colorinlistoftodos]{todonotes}
\pagestyle{fancy}
\setlength{\headheight}{65pt}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{sol}
    {\emph{Solution:}
    }
    {
    \qed
    }
\specialcomment{com}{ \color{blue} \textbf{Comment:} }{\color{black}} %for instructor comments while grading
\NewEnviron{probscore}{\marginpar{ \color{blue} \tiny Problem Score: \BODY \color{black} }}

\newcounter{subproblem}
% \renewcommand{\thesubproblem}{\alph{subproblem}} % letters 
\renewcommand{\thesubproblem}{\arabic{subproblem}} % numbers
\newenvironment{subprob}[1][]{
  \refstepcounter{subproblem}
  \begin{trivlist}
  \item[\hskip \labelsep {\bfseries (\thesubproblem)}]
}{
  \end{trivlist}
}
\newenvironment{subsol}
    {\emph{Solution:}
    }
    {
    \qed
    }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbff{Z}}
\newcommand{\st}{\text{s.t}}

\usepackage{listings}
\usepackage{xcolor}
\lstset{
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{gray!10},
  frame=single,
  breaklines=true,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  language=Matlab
}

\setlength {\marginparwidth }{2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Fill in the appropriate information below
\lhead{Class: ECON 20210}
\chead{Assignment: 2}
% \lhead{Anthony Yoon}  %replace with your name
\rhead{Anthony Yoon\\ Min Seo Kim \\ Sam Konkel \\ Pratyush Sharma} %replace XYZ with the homework course number, semester (e.g. ``Spring 2019"), and assignment number.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Do not alter this block.
\begin{document}
\listoftodos
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problem}{1}
    Explaining lower real interest rates. 
\end{problem}
\begin{subprob}
\end{subprob}
\begin{subsol}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{fredgraph.png}
        \caption{Fred Graph}
        \label{fig:enter-labe1l}
    \end{figure}
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    $n_{90} = 0.0122699866, g_{90} = 0.00785, \delta_{90} = 0.05, s_{90} = 0.07$\\
    $n_{10} = 0.00679, g_{10} = 0.0044, \delta_{10} = 0.04, s_{10} = 0.073$
\end{subsol}
\begin{subprob}
    
\end{subprob}
\begin{subsol}
    We can see that $r = \frac{\partial Y}{\partial K_t} - \delta$. We can compute this as the following:
    \[
    \frac{\partial Y}{\partial K_t} = \alpha K_t^{\alpha - 1} (A_t N_t)^{1-\alpha} = \alpha k^{\alpha - 1}
    \]
    In steady state, note that $\Delta k_t = 0$. This implies that
    \begin{align*}
        \Delta k_t &= s k_t^\alpha - (n + g + \delta)k_t\\
        0 &= sk_t^\alpha - (n + g + \delta)k_t\\
        \frac{n + g + \delta}{s} &= k_t^{\alpha - 1}\\
        \alpha \frac{n + g + \delta}{s} &= \alpha k_t^{\alpha - 1}
    \end{align*}
    Thus, 
    \[
    r = \alpha \frac{n + g + \delta}{s} - \delta
    \]
\end{subsol}
\begin{subprob}
    Let $\alpha = \frac{1}{3}$. We can see that:
    \[
    r_{90} = \frac{0.0-123+ 0.0079 + 0.05}{3(0.073)} - 0.05 = 0.2689
    \]
    \[
    r_{10} = \frac{0.0068 + 0.0044 + 0.04}{3(0.073)} - 0.05 = 0.183
    \]
    we can see that the model successfully explains the decline in the real interest. We can see that the model slightly overestimates the interest rates for both time frames, but the average difference is congruent over both time periods. 
\end{subprob}

\begin{subprob}
\end{subprob}
\begin{subsol}
    % The Real Treasury Yield is not a good estimate for the Solov model's growth rate. 
    % Real Treausry Yield will be lower than the solov model, because treasury yield are risk free (low risk) and inside solov model, r is return on physical captial, which is inherentlt riskier than the treasury yield. 
    The real Treasury yield is not a suitable measure for the real interest rate $r$ in the Solow model. Treasury yields reflect returns on risk-free government debt, wheras while 
    $r$ in the Solow model represents the return on physical capital, which is riskier and therefore commands a higher return


    Since Treasury bonds do not account for the risk premium inherent in capital investment, their yields are typically lower than the actual return on capital. As a result, using real Treasury yields would underestimate 
    $r$ and misrepresent investment incentives in the model.
\end{subsol}


\setcounter{subproblem}{0}
\begin{problem}{2}
    Transitional Dynamics in Solow Growth Model
\end{problem}
\begin{subprob}

\end{subprob}
\begin{subsol}
    Given the given parameters, we can see that:
    \[
k_t = \frac{K_t}{A_t N_t} \quad y_t = \frac{y_t}{A_tN_t} 
\]
Thus
\begin{align*}
    K_{t+1} &= K_t(1-\delta) + I_t\\
    K_{t+1} &= K_t(1 - \delta) + s(A_t N_t)^{1-\alpha} K_t^\alpha\\
    K_{t+1} - K_t &=  s(A_t N_t)^{1-\alpha} K_t^\alpha - \delta K_t\\
    \frac{\Delta K_t}{K_t} &= \frac{s(A_t N_t)^{1-\alpha} K_t^\alpha}{K_t} - \delta \\
    \frac{\Delta K_t}{K_t} &= \frac{s K_t^{\alpha - 1}}{(A_t N_t)^{\alpha -1}} - \delta \\
    \frac{\Delta K_t }{K_t} &= s k_t^{\alpha -1} - \delta\\
\end{align*}
Note that $K_t = A_t N_t k_t$ This implies:
\begin{align*}
    \frac{\Delta K_t }{K_t} &= s k_t^{\alpha -1} - \delta\\
    \frac{\Delta k_t A_t N_t}{k_t A_t N_t} &= s k^{\alpha - 1}_t - \delta \\
    \frac{\Delta k_t}{k_t} + \frac{\Delta A_t}{A_t} + \frac{\Delta N_t}{N_t} &= sk_t^{\alpha - 1} - \delta\\
    \frac{\Delta k_t}{k_t} + g + n &= sk_t^{\alpha - 1} - \delta\\
    \Delta k_t &= sk_t^\alpha - (n + g + \delta) k_t
\end{align*}
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    At steady state, $\Delta k_t = 0$ For notational state, let $x = k_{ss}$. This implies that
    \begin{align*}
        0 &= sx^\alpha - (n+g+\delta)k_t\\
        (n+g+\delta)x &= sx^\alpha\\
        \frac{n+g+\delta}{s} &= x^{\alpha - 1}\\
        x &= \left( \frac{s}{n+g+\delta} \right)^\frac{1}{1-\alpha} 
    \end{align*}
\end{subsol}
\begin{subprob}
    
\end{subprob}
\begin{subsol}
    We are interested in the following optimization problem:
    \begin{align*}
        \max & \quad k_t^\alpha - (n+g+\delta)k_t
    \end{align*}
    Taking the first order deriative with respect to $k_t$ allows to see:
    \[
    \alpha k_t^{\alpha - 1} - (n+g+\delta) = 0 \implies k_{gr} = \left( \frac{\alpha}{n+g+\delta} \right)^\frac{1}{\alpha -1}
    \]
    This implies that $ s = \alpha$
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    Code for the simulation:
    \begin{lstlisting}
 % Setting parameters
s = 0.4;
delta = 0.06;
n = 0.02;
g = 0.02;
alpha = 1/3;
z = 100; % Number of iterations

% x axis creation
X = 0:1:z;
X = X';

K = zeros(z+1, 1);
A = zeros(z+1, 1);
N = zeros(z+1, 1);
k = zeros(z+1,1);
y = zeros(z+1,1);
Y = zeros(z+1,1);

% setting values
A(1) = 1;
K(1) = 1;
N(1) = 1;
Y(1) = K(1)^alpha * (A(1) * N(1))^(1-alpha);

% Time iteration 
for i = 1:(z+1)
    A(i + 1) = A(i) * (1 + g);
    N(i + 1) = N(i) * (1 + n);
    K(i + 1) = K(i) * (1 - delta) + s * (A(i) * N(i))^(1 - alpha) * K(i)^alpha;
    k(i) = (K(i) / (A(i) * N(i)));
    Y(i) = K(i)^alpha * (A(i) * N(i))^(1-alpha);
    y(i) = Y(i) / (A(i) * N(i));
end

figure;

subplot(2, 2, 1);
plot(X, y);
title('Plot of y vs X');
grid on;

subplot(2, 2, 2);
plot(X, Y);
title('Plot of Y vs X');
grid on;

subplot(2, 2, 3);
plot(X, k);
title('Plot of k vs X');
grid on;

subplot(2, 2, 4);
plot(X, K(1:101));
title('Plot of K vs X');
grid on;
    \end{lstlisting}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{ECON20210P3Q5.pdf}
    \caption{Figure Econ 20210 Problem 3 Question 5}
    \label{fig:enter-label}
\end{figure}
Note that $k$ and $y$ are appraoch the steady state behaviors and $Y$ and $K$ approach infinity, which resemble the Inada conditions. 
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    \begin{lstlisting}
% Problem 3 Q5

% Setting values 
k_steady_state = (s / (n+g+delta))^(1.5);
k_1 = zeros(z, 1);
k_1(1) = k_steady_state;
s = 0.35;

for i=1:z
    k_1(i+1) = s * k_1(i)^alpha - (n + g + delta) * k_1(i) + k_1(i);
end

figure;

plot(X,k_1)
    \end{lstlisting}
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{ECON20210P3Q6.pdf}
        \caption{Graph for Part 5 of Question 3}
        \label{fig:en1212ter-label}
    \end{figure}
\end{subsol}

\begin{subprob}
\end{subprob}
\begin{subsol}
    Note that $c = (1-s)y_{ss} = (1-s)k_{ss}^\alpha$. Since consumption is higher in new path, as savings rate has decreased and $k_{ss}$ has decreased, we know that this new path is more dynamically efficient as savings rate is closer to the golden rule savings rate.
\end{subsol}

\setcounter{subproblem}{0}

\newpage
\begin{problem}{3}
    
\end{problem}
\begin{subprob}
\end{subprob}
\begin{subsol}
    We can see the law of depreciation is:
    \[
    W_{t+1} = W_t - c_t \quad \st \quad W_0 > 0
    \]
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    Note that:
    \begin{align*}
        W_{t+1} &= W_t - c_t\\
        c_t &= W_t -W_{t+1}
    \end{align*}
    We can see that the net consumption is:
    \begin{align*}
        \sum_{t = 0}^{T} c_t  &= \sum_{t = 0}^{T} W_t - W_{t+1}\\
        &= (W_0 - W_1)  + (W_1 - W_2) + \dots - W_t + W_{T+1}\\
        &= W_0 - W_{T+1}
    \end{align*}
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    We can see that the Langrangian with the following assumptions are:
    \[
    L = \sum_{t=0}^{T} \left\{\beta^T u(c_t) + \lambda_t (W_t - W_{t+1} - c_t)\right\} + \mu W_{T+1}
    \]
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    We can see now that 
    \begin{align*}
        \frac{\partial L}{\partial c_t} &= \beta^t u'(c_t) - \lambda_t = 0\\
        \frac{\partial L}{\partial W_t} &= \lambda_t - \lambda_{t-1} = 0 \quad \forall t \in \{0,1,2,\dots,T\}\\
        \frac{\partial L}{\partial W_{T+1}} &= -\lambda_T + \mu = 0
    \end{align*}
    We have the following complentary slackness conditions:
    \begin{align*}
        \mu W_{T+1} &= 0 \\
        \lambda_t(W_t - W_{t+1} - c_t) &= 0
    \end{align*}
    We can see that if $\mu = 0$, that implies that every $\lambda = 0$, which is a contradiction. Therefore, we can see that $\mu > 0$ implies that $W_{t+1} = 0$, which sastifies the FOCs and complentary slackness conditions. 
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    From a $[c_{i+1}]$ and $[c_i]$, we see that:
    \[
    u'(c_{t+1})  = \frac{\lambda}{\beta^{t+1}} \quad u'(c_t) = \frac{\lambda}{\beta^t}
    \]
    This implies
    \[
    \frac{u'(c_{t})}{u'(c_{t+1})} = \frac{\frac{\lambda}{\beta^t}}{\frac{\lambda}{\beta^{t+1}}} = \beta \iff u'(c_t) = \beta u'(c_{t+1})
    \]
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    From (4), we see that 
    \[
    \frac{1}{c_t} = \frac{\beta}{c_{t+1}} \iff \frac{c_{t+1}}{\beta} = c_t
    \]
    Therefore, we can see that since $W_{T+1} = 0$, this implies that:
    \begin{align*}
        c_T &= W_T\\
        c_{T-1} &= \frac{1}{\beta} W_T \\
        c_0 &= \frac{1}{\beta^T}W_T
    \end{align*}
    Therefore, we can sum all of this up and get that:
    \[
    \sum_{t = 0}^{T} c_t = W_T \sum_{t = 0}^{T} \frac{1}{\beta^t}
    \]
\end{subsol}
% \begin{problem}{3}
%     Cookie Eating - Part 1
% \end{problem}

% \begin{subprob}
% \end{subprob}
% \begin{subsol}
%     Note that $W_{t+1} =  W_t - c_t$ and thus $W_t = W_{t-1} - c_{t-1}$. This implies that via a recursive arguement:
%     \[
%     W_{t+1} = W_t - c_t \implies W_{t+1} = W_0 - \sum_{t = 1}^{T} c_t 
%     \]
%     such that $W_{t+1} \geq 0 $
% \end{subsol}
% \begin{subprob}
% \end{subprob}
% \begin{subsol}
%     The Langrangian is as follows:
%     \[
%     L = s - \lambda \left( W_{t+1} - W_0 + \sum_{0}^{t} c_t \right)
%     \]
%     with the following FOCs:
%     \begin{align*}
%         [c_i] & \quad \left(\frac{\partial u}{\partial c} \bigg|_{c_i}\right) \cdot \beta^i + \lambda \leq 0\\
%         [\lambda] & \quad W_{t+1} \leq W_0 - \sum_{t = 1}^{T} c_t 
%     \end{align*}
%     Note that $W_{t+1}$ has to be 0, as no utility is derived from $W_{t+1}$ period. 
% \end{subsol}
% \begin{subprob}
% \end{subprob}
% \begin{subsol}
%     From a $[c_{i+1}]$ and $[c_i]$, we see that:
%     \[
%     u'(c_{t+1})  = \frac{\lambda}{\beta^{t+1}} \quad u'(c_t) = \frac{\lambda}{\beta^t}
%     \]
%     This implies
%     \[
%     \frac{u'(c_{t})}{u'(c_{t+1})} = \frac{\frac{\lambda}{\beta^t}}{\frac{\lambda}{\beta^{t+1}}} = \beta \iff u'(c_t) = \beta u'(c_{t+1})
%     \]
% \end{subsol}
% \begin{subprob}
% \end{subprob}
% \begin{subsol}
%     From (4), we see that 
%     \[
%     \beta c_t = c_{t+1} \iff \frac{c_t}{\beta} = c_{t-1}
%     \]
%     This implies that using the $[\lambda]$ condition, we are innterested in solving:
%     \[
%     W_0 = \sum_{i = 0}^{t} \beta^{-i} c_t 
%     \]
%     which is equivalent to 
%     \[
%     c_t \sum_{i=0}^{t} = W_0 \iff c_t = \frac{W}{\sum_{i=0}^{t} \beta^{-i}}
%     \]
% \end{subsol}
% \todo{Do final part}
\setcounter{subproblem}{0}
\begin{problem}{4}
    Crusoeâ€™s Intratemporal Choice
\end{problem}
\begin{subprob}
\end{subprob}
\begin{subsol}
\begin{align*}
    \max & U(c, l)\\
    \st & \quad c = \frac{1}{1-\theta} (l - \overline{l})^{1-\theta}\\
    \st & \quad 0 < \theta < 1
\end{align*}
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    The FOCs are as follows:
    \begin{align*}
        [c] & \quad \frac{\alpha}{c} - \lambda = 0\\
        [l] & \quad \frac{1-\alpha}{1-l} - \lambda(l - \overline{l})^{-\theta} = 0\\
        [\lambda] & \quad c = \frac{1}{1-\theta} (l - \overline{l})^{1-\theta} 
    \end{align*}
    We see that using the $[l]$ and $[\lambda]$ constraint, we see that
    \begin{align*}
        -\frac{1-\alpha}{1-l} + \frac{a}{c} (l -\overline{l})^{-\theta} &= 0\\
        \frac{\alpha}{c} (l - \overline{l})^{-\theta} &= \frac{1-\alpha}{1-l}\\
        \frac{\alpha}{c(l-\overline{l})^\theta} &= \frac{1-\alpha}{1-l}
    \end{align*}
    Note that $(l - \overline{l})^{\theta}$ is the weight of trade off between the consumption and labor. If $\theta$ increases, working more does become as beneifical. 
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    Using the derived optimality condition, we can see the following:
    \begin{align*}
        \frac{1-\alpha}{1-l} &= \frac{\alpha}{c} (l - \overline{l})^{-\theta}\\
        c(1-\alpha) &= \alpha (1- l )(l - \overline{l})^{-\theta}\\
        c &= \frac{\alpha (1-l)(l- \overline{l})^{-\theta}}{1-\alpha}\\
        \frac{1}{1-\theta} (l - \overline{l})^{1-\theta} &= \frac{\alpha (1-l)(l- \overline{l})^{-\theta}}{1-\alpha}\\
        \frac{l - \overline{l}}{1-\theta} &= \frac{\alpha (1-l)}{1-\alpha}\\
        \frac{l}{1-\theta} + \frac{\alpha l}{1-\alpha} &= \frac{\alpha}{1-\alpha} + \frac{\overline{l}}{1-\theta}\\
        l \left( \frac{1}{1-\theta} + \frac{\alpha}{1-\alpha} \right) &= \frac{\alpha (1-\theta) + \overline{l} (1-\alpha)}{(1-\alpha)(1-\theta)}\\
        l \left( \frac{1-\alpha + \alpha(1-\theta)}{(1-\theta)(1-\alpha)} \right) &= \frac{\alpha (1-\theta) + \overline{l} (1-\alpha)}{(1-\alpha)(1-\theta)}\\
        l &= \frac{\alpha (1-\theta) + \overline{l} (1 - \alpha)}{1-\alpha + \alpha(1-\theta)}
    \end{align*}
    This implies that:
    \begin{align*}
        c &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \overline{l}(1 - \alpha)}{1 - \alpha + \alpha(1 - \theta)} - \overline{l} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \overline{l}(1 - \alpha)}{1 - \alpha + \alpha - \alpha\theta} - \overline{l} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \overline{l}(1 - \alpha)}{1 - \alpha\theta} - \overline{l} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \overline{l}(1 - \alpha) - \overline{l}(1 - \alpha\theta)}{1 - \alpha\theta} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \overline{l}[(1 - \alpha) - (1 - \alpha\theta)]}{1 - \alpha\theta} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \overline{l}(\alpha\theta - \alpha)}{1 - \alpha\theta} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta) + \alpha(\theta - 1)\overline{l}}{1 - \alpha\theta} \right)^{1 - \theta} \\
          &= \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta)(1 - \overline{l})}{1 - \alpha\theta} \right)^{1 - \theta}
        \end{align*}
        Therefore:
        \[
           l^* = \frac{\alpha (1-\theta) + \overline{l} (1 - \alpha)}{1-\alpha + \alpha(1-\theta)} \quad c^* = \frac{1}{1 - \theta} \left( \frac{\alpha(1 - \theta)(1 - \overline{l})}{1 - \alpha\theta} \right)^{1 - \theta}
        \]        
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    \[
    \frac{\partial l}{\partial \overline{l}} = \frac{1-\alpha}{1-\alpha + \alpha(1-\theta)} \quad 
    \frac{\partial c}{\partial \overline{l}} = -\left( \frac{\alpha(1 - \theta)}{1 - \alpha\theta} \right)^{1 - \theta} (1 - \overline{l})^{-\theta}
    \]
    Note that $\frac{\partial l}{\partial \overline{l}} > 0$ and $\frac{\partial c}{\partial \overline{l}} < 0$ We can see that this implies that increasing $\overline{l}$ means that $l$ increases and $c$ decreases. We can also observe the same in the following diagram. 
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.75\linewidth]{ECON20210Q4-4.jpeg}
        \caption{Graph for Question 4, part 4}
        \label{fig:enter-label123423}
    \end{figure}
    The red denotes the shift in caused by an increase in $\overline{l}$. We can see that increasing the innate fixed cost to producing, the person must still work more to produce items to consume. The person still needs to consume items to derive utility, hence why labor increases. 
\end{subsol}
\begin{subprob}
\end{subprob}
\begin{subsol}
    We can see the langrangian as follows:
    \[
    L = \alpha \ln(c) + (1-\alpha) \ln(1-l) + \lambda \left(c - \frac{1}{1-\theta}(l - \overline{l})^{1-\theta}\right) + \mu (\hat{l} - l)
    \]
    We see that the followng FOCs hold:
    \begin{align*}
        [c] & \quad \frac{\alpha}{c} + \lambda c = 0\\
        [l] & \quad -\frac{1-\alpha}{1-l} - \lambda (l -\overline{l})^{-\theta} - \mu = 0\\
        [\lambda] & \quad c - \frac{1}{1-\theta}(l - \overline{l})^{1-\theta} \leq 0 \\
        [\mu] & \quad l - \hat{l} \hspace{10pt} ? \hspace{10pt} 0 
    \end{align*}
    If $l^* - \hat{l} \leq 0$, we can see that we are left with an original optimization problem as seen before, as $\mu = 0$. However, there remains the case where $\hat{l} > l^*$. If this is the case, note that this implies that $\mu > 0 $. If this is the case, we can set $l = \hat{l}$, and thus find that the optimal solution would be:
    \[
    l = \hat{l} \quad c = \frac{1}{1-\theta}(\hat{l} - l)^{1-\theta}
    \]
\end{subsol}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Do not alter anything below this line.
\end{document}