\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{hyperref} 
\usepackage{amsmath}
\usepackage{ gensymb }
\usepackage{ amssymb }
\usepackage{float}
\usepackage{amsthm}
\usepackage{float}


\newcommand{\st}{\text{s.t}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}

\title{Econ 20110 Notes}
\author{Anthony Yoon}
\date{January 2025}
\begin{document}
\maketitle
\tableofcontents
\section{Production Theory}
Weeks 1 and 2\\
In economics, we are concerned about constrained optimization, where we see that we want to optimize a parameter given some constraints. In Econ 20010, we were mainly concerned about the two good case, $x_1. x_2$, but now we are concerned about vectors, which are general collections of objects. In this case, we can be concerned about vectors, denoted by \textbf{bold} letters, like $\mathbf{x}$, essentially are any amount of goods that we are interested in. These problems present themselves in the form 
\begin{align*}
    \max_{\mathbf{X}} & \quad U(\mathbf{x})\\
    \st & \quad \mathbf{p} \cdot \mathbf{x} \leq m
\end{align*}
We can see that generally speaking, we have an objective function (the utility function), and choice vectors ($\mathbf{x}$). But we can also introduce the notion of paramter vectors, denoted as $\theta$. In [ump], these were prices and the budget and in the [emp], these where denoted as prices and utility. Now when we solve these equations, we see that we were able to derive a solution function, usually the Marshallian or the Hicksian demand functions. But we can generalize these kind of functions to that of solution functions, which are functions that . One thing we can note is that whenever we solve an optimization problem, we are not only solving for the solution function, we are solving for whole class of functions that allow us to see behavior as parameters change etc. Hence, we can find the following:
\begin{itemize}
    \item \textbf{Solution Function}: Optimal solution as a function of $\theta$. Ex. Marshallian and Hicksian
    \item \textbf{Value Function}: What is the optimized value as a function of $\theta$. Ex. Indirect Utility function, Expenditure Function
    \item \textbf{Envelope Theroem}: We can use this to link the value function to the solution function
\end{itemize}
\subsection{Kuhn Tucker Theroem}
Up to this point, we have assumed that everything is nice within optimization problems, where in the first order condtions, we can see that for $i \in I$ where $I$ is an indexing set
\[
\frac{\partial L}{\partial x_i} = \frac{\partial U}{\partial x_i} - \lambda p_i = 0
\]
but from now on, we cannot assume that as that is not representive of the real world. Instead, we have to consider first order conditions such that
\[
\frac{\partial L}{\partial x_i} =  \frac{\partial U}{\partial x_i} - \lambda p_i \leq 0 \quad x_i \geq 0
\] 
\[
\frac{\partial L}{\partial \lambda} = m - \sum_{i=1} p_i x_i \geq 0 \quad \lambda \geq 0 
\]
where we introduce complementary slackness into each condition. Before we discuss what this means, we can introduce the idea of \emph{interior solutions}. When we do this, consider an interval $[a,b]$. Let $c \in [a,b]$. If $f'(c) = 0$, then it is a optimzer, but we can also consider the endpoints, $a,b$. If the endpoints contain the maximum/minimum value, we can see that there are actually the minimizer and maximumizer values themselves, but the values of the first order conditions can be positive or negative. Hence, we introduce complemntary slackness. We can consider $x_i \in [0, \infty)$ as denoted by the restriction. If $x_1 \in (0,\infty)$ then the first order condition must be strict equality. If $x_1 = 0$, then we know that the first order condition can include the case where the deriative may be negative. Note that these statements are if and only if statements. 


From here, we can make educated guesses about what we think the intial conditions are. These can be any combination of $x_i > 0$, $x = 0$, $\mathbf{p} \cdot \mathbf{x} < m$ or $\mathbf{p} \cdot \mathbf{x} = m$ \footnote{Vector dot products mean that we really are doing $p_1 x_1 + p_2 x_2 + \dots p_n x_n$}. However, we can see that we already know that $\mathbf{p} \cdot \mathbf{x} = m$ as any consumer will derive more utility from increased consumption, so the consumer must spend all of their income. 


However, what each $x_i$ should be is dependent on the mathematical and economic intuition. Consider the utility function
\[
U(x_1, x_2) = \ln(x_1) + \ln(x_2)
\]
we can see that 
\[
\frac{\partial u}{\partial x_1} = \frac{1}{x} 
\]
which is $\infty$ 
\subsection{Production Technology}
People on the demand side are refered to consumers and those who are on the supply-side are firms. \textbf{Firms are the organizer of production}, where these firms thake in inputs into outputs. If we wanted to be specific, we can see that firms are tasked with the question of given a set of inputs, what is the ideal output. Such choices are constrained by the production technology available to the firms.  


Mathematically spaking, we can see that input choices are members of the set $X \subseteq \mathbb{R}^m_+$ and similarly, output choices are members of the set $Y \subseteq \mathbb{R}^n_+$. Thus, when we take the cartesian product of these two sets, we get the \textbf{production possibility set}, or mathematiclly speaking $F \subseteq X \times Y$. So essentially, it is a tuple of values (for the sake of arguement, say $(x_1, x_2, \dots x_m, y_1, y_2, \dots y_m)$). So given a set of inputs $(x_1, x_2 \dots, x_m$, we can see that it produces $y_1, y_2, \dots d_n)$. However, there are restrictions on the proudction possibilities. A machine can only make certain amount of outputs for a set of given inputs only for a certian time interval. So for example:
\[
F = \{(x,y) \in \mathbb{R}^2_+ \quad | \quad y \leq 0.5x\}
\]
But most times, economicsts are interested in the outputs given a set of labor and capital. These will be reflected in restriction type of the production possiblities set. 
An example of this is $k$, which is a fixed cost. Intuitvely, we can see that it would take $k$ hours to start a process.


However, this comes with a key assumption. This assumption is that $y$ has an upper bound. This upper bound is the output given maximum efficieny. However, consider the case where there are no efficient methods. in that case, there are so inputs that go to waste. If we can dispose of these inputs costly, that is considered free disposal. This is, however, unrealistic, as in some cases these byproducts are harmful to dispose of. 
\subsection{Production Functions}
For simplicities sake, we are only considering idea where given many input, we are only getting a singular output. Assuming maximum efficiency, we can define a production function as $f: \R^m_+ \to \R_+$ be defined by
\[
f(x_1, x_2, \dots x_m) := \sup \{y \in \R_+ \quad | \quad (x_1, x_2, \dots, x_m, y )\in F \}
\]
And for the sake of simplicity, assume that the production function is continous, strictly increasing, and strictly quasiconcave on $\R_+^m$ and $f(\mathbf{0}) = 0$. This makes make things easier.  
\subsection{Some math termialogy}
For any two vectors $\mathbf{x}, \mathbf{y} \in \R^n$, we write thet 
\begin{itemize}
    \item $\mathbf{x} \geq \mathbf{y}$ if $x_i \geq y_i$ for all $i = 1,2, \dots, n$
    \item $\mathbf{x} >> \mathbf{y}$ if $x_i > y_i$ for all $i = 1, 2, \dots, n$. 
    \item $\mathbf{x} > \mathbf{y}$ if $\mathbf{x} \geq \mathbf{y}$ and $\mathbf{x} \neq \mathbf{y}$
\end{itemize}
A function $f: \R^n \to \R$ is strictly increasing if $f(\mathbf{x}) > f(\mathbf{x})$. 
\subsection{Analyzing the key assumption of production functions}
The assumption that roduction function is continous, strictly increasing, and strictly quasiconcave on $\R_+^m$ and $f(\mathbf{0}) = 0$ has the implications that 
\begin{itemize}
    \item Contunitity means that small changes in input lead to small changes in output
    \item Strict Contunitity means that small changes in input will cause changes in output. 
    \item Strict quasiconcavity means that averaging production plans yields higher output, sort of like the utility curves of last quarter.
\end{itemize}
\subsection{Comparitive statics}
Often times, we are interested in what small changes in input entails. Liek always, assume ceterbis paribus conditions. Assume that $f$ is differentiable, which means that we can now get the marginal product of input i, as 
\[
MP_i(\mathbf{x}) = \frac{\partial f(\mathbf{x})}{\partial x_i}
\]
which is similar to marginal utility. Note that this value is dependent on the input vector. Similarly, we can see that the marginal rate of technical substitution between inputs $i$ and $j$
\[
MRTS_{ij}(\mathbf{x}) = \frac{MP_i(\mathbf{x})}{MP_j(\mathbf{text})}
\]
We can also have isoquants, which are the set of all inputs that output the same thing. Note thate absolute value of the slope is given by the MRTS. There is a proof of this on his notes. The quasiconcavity assumption iplies that isoquants bend towards the origin, which means that MRTS is diminishing. 
\subsection{Returning to scale}
We also can look at how output changes as we vary all inputs while holding the input proportions (ratios) constant. We can say that 
\begin{itemize}
    \item \textbf{Constant Return to Scale}: If $f(tx) = tf(x)$ for all $\mathbf{x} \in \R^m$ and all $t \in \R_+$. AKA, Homogeneous of degree one. 
    \item \textbf{Increasing return to scale}: $f(tx) > tf(x)$ for all $x \in \R^m_+$ and all $t > 1$
    \item \textbf{Decreasing return to scale}: $f(tx) < tf(x)$ for same conditions as increasing to scale
\end{itemize}
There is also the elasitcity of substitution, which is: 
\[
\sigma_{ij} = \frac{d \ln \left( \frac{x_j}{x_i} \right)}{d \ln(MRTS_{ij}(\mathbf{x})))}
\]
larger $\sigma$ means that it is easier to substitute between two things.   
\subsection{Competitive Firm Behavior}
We believe that firms maximize profit. However, we can put in other considerations into this assumption, as firms may have other priorties. We also assume that the product market and the input markets should be \textbf{Perfectly Competitive}. This means that the consumption of the good does not affect the price, so the output and input behaviors are taken as given. This is can be seen as "Price Taking Behavior". Thus, a firm is interested in solving the following optimization problem:
\begin{align*}
    \max_{y, x_1, x_2, \dots, x_m} & \quad py - \sum_{i =1}^m \omega_i  x_i \\
    \st & \quad y = f(x_1,x_2, \dots, x_m)
\end{align*}
but also, note that the following is mathematically sound:
\[
\max_{x,y} f(x,y) = \max_{y'} \max_x f(x; y')
\]
and the $\arg \max$ arguement still holds. When we analyze the above quantity, we see that the follwing maxization problem is equivalent:
\[
    \max_y py - \min_{x_1, x_2, \dots, x_m} \sum_{i =1}^m \omega_i x_i
\]
Thus, we can break thsi down into 2 steps. 
\begin{itemize}
    \item First, solve for every potential output level $y$, an cost minimization problem.
    \item Then, we choose the profit maximizing output level y after taking taking the minimized cost for every $y$ as given. 
\end{itemize}
\subsection{Cost-minimization}
We are interested in finding the minimum costing input bundle that yields at least any arbitrary given level of outputs. Hence,
\begin{align*}
    \min_{x_1, x_2, \dots, x_m} & \quad \sum_{i =1}^{m} \omega_i x_i\\
    \st & \quad f(x_1, x_2, \dots, x_m) \geq y
\end{align*}
And thus, we can go through the same KTT process as we did for any constrained optimizatino problem. However, note that we are working with \emph{minimization}, hence, for $i = 2, 3, \dots, m$. 
\[
\frac{\partial L}{\partial x_i} = \omega_i - \lambda \frac{\partial f(x)}{\partial x_i} \geq 0
\]
We can solve this in a very similar way to do that of last quarter, where we can find the solution function, in the form $x(\mathbf{\omega}, y)$. We call these \emph{Conditional Input Demand Function}, where we are concerend about functions in the form $x(\mathbf{\omega}, y)$. Thus, we can have a minimized cost function, that would be $c(\mathbf{\omega}, y) = \mathbf{\omega} \cdot \mathbf{x}$
\subsection{The Cost Function}
So we have solved for the minimum value, and we can solve the optimization problem as $\sum_{i =1 }^m \omega_i x_i^*$. Sum and substitute for proper values, and you will get the profit in terms of $y$ and other parameters.


But what happens to a graphical perspective. To reiterate, an isoquant is the set of all inputs that produce a certain output (AKA utility equivalent). Iso-costs is the budget constraint. Graphically, this is the tangency image that is repeated a lot in conumser theory. 
\subsection{Cost minimization}
Theorem: If $f$ is continuous and strictly increasing and $\mathbf{\omega} >> 0$, then $c(\mathbf{\omega}, y)$ is strictly increasing in $y$. 

We can argue this because when $f(x)$ and $c(\omega, y)$ are differentiable (which is guaranteed when f is also quasi-concave) and $f_i(x) > 0$ for all $i$ and $\mathbf{x}$. This implies that when there is no free inpu, margianl cost of production is always positive. We can also average 
\[
AC(\omega, y) = \frac{c(\omega, y)}{y}
\]
We have already proven in the HW that if the fucntion exhibits constant, inreasing, or decreasing return to scale, we see that tha leads to constant, decreasing, increasing respectively return to scale. Note that if we were to change the input prices by the same proprotion, we actually do not change the actual relative price. Thus, our input levels should not change, which implies that the \emph{the conditional input demand functions are homoegnous of degree zero in prices}. But, a collorary of this is that the cost function is homoegnous in egree one in regards to $\omega$. 


As a byproduct of this, we can see that the Envelope Theorem gives us Shepard's Lemma, if $f$ is strictly quasiconcave, then:
\[
\frac{\partial c(\mathbf{\omega}, y)}{\partial \omega_i} = x_i^*(\mathbf{\omega}, y)
\]
We can see that the cost function is (weakly) increasing in $\omega$. what this entails is that if we can achieve lower cost with higher price, subject to the same constraints, we were not optimal to begin with. In fact, this also entails that $c(\omega, y)$ is concave in $\omega$. \\
Now we have the substitution matrix, which is the Hessian matrix of $c(\omega, y)$, which corresponds to the Hessian Matrix of $c(\omega, y)$ which is concave in $\omega$. \footnote{I am not the best at this}. It is seen here as 
\[
\mathbf{\sigma^*}(\omega, y) = \begin{bmatrix}
    \frac{\partial x_1(\omega, y)}{\partial \omega_1} & \frac{\partial x_1(\omega, y)}{\partial \omega_2} & \dots & \frac{\partial x_1(\omega, y)}{\partial \omega_n} \\
    \frac{\partial x_2(\omega, y)}{\partial \omega_1} & \frac{\partial x_2(\omega, y)}{\partial \omega_2} & \ddots & \frac{\partial x_2(\omega, y)}{\partial \omega_n}\\
    \vdots & \ddots & \ddots & \vdots \\
    \frac{\partial x_n(\omega, y)}{\partial \omega_1} & \dots & \dots & \frac{\partial x_n(\omega, y)}{\partial \omega_n}
\end{bmatrix}
\]
And from a proof that I frankly will not be doing, we know that $\sigma^*$ is symmetric and negative semidefinite, which means that all $\frac{\partial x_i(\omega, p)}{\partial \omega_i} \leq 0$ 
\subsection{Hessian Matrix Breakdown}
Intuitvely, the Hessian Matrix refers to the local curvature around a certain point. We have varying types of curavture, which are characterized by differing forms of a matrix. They are as follows:
\begin{itemize}
    \item A Positive Definite Matrix M means that for all $x \in \R^n \setminus \{0\}$, $x^T M x >0$ and that all eigenvalues are positive.
    \item A Positive Semi-Definite Matrix M means that for all $x \in \R^n$, we know that $x^T M x \geq 0$ and all eigenvalues are non-negative (so this means that the eigenvalue can be 0)
    \item I'll fill in this later 
\end{itemize}
\subsection{Short Run Cost Function}
So far we have assumed that firms are able to change all of their inputs when minimizing their production costs. However, it is assumed that this is only true in the long run. In the short run, there are some things that are not so easily changible. I.E, you can't build a building within 2 days. Thus, we can write a firm's short run cost minimization as follows:
\begin{align*}
    \min_{x_1, x_2, \dots, x_j} & \quad \sum_{i = 1}^{I} \omega_i x_i + \sum_{i = 1}^{J} \overline{\omega}_j \overline{x}_j 
\end{align*}
where any variable that has a bar over it like $\overline{x}$, that corresponds to a short run function. Thus, we see tha the short run cost cannot be lower than the long run (minimized) cost. Thus, for $sc \geq c$. However, to enforce strict equality, note that if over long term conditional input demand functions equal our $\overline{x}$, than we know that 
\[
sc(\mathbf{\omega}, y ; \mathbf{\overline{x}}(\mathbf{\omega}, y)) = c(\mathbf{\omega}, y)
\]
If the above is true, than we know that our chosen $\mathbf{\overline{x}}$ must minimize short cost at our desired parameters. Thus, we see that 
\[
\frac{\partial sc(\omega, y ; \mathbf{\overline{x}}(\mathbf{\omega}, y))}{\partial \overline{x}_j} = 0
\]
for all $j \in \N$. Note that for a gievn value of $y$, we can make the short run cost equal the long term cost also implies that they are also tangent to each other. 
\subsection{Direct Profit Maximization}
Note to this point, we have been interested in solving the problem:
\begin{align*}
    \max_{(y, x_1, x_2, \dots, x_m)} & \quad py - \sum_{i=1}^{m} \omega_i x_i\\
    \st & \quad y = f(x_1, x_2, \dots, x_m)
\end{align*}
Up till this point, we have been motivated to solve this in two steps: (1) find the cost minimized inputs, then (2) maximize the profits for a given level of outputs. Here, we are interested in this solving in two steps. We can substute the constraint into our objective function to get the following:
\[
\max_{x_1, x_2, x_3, \dots, x_m} pf(x_1, x_2, \dots, x_m) - \sum_{i = 1}^m \omega_i x_i
\]
We can see that if we assume interior solutions, we see that the FOCs are 
\[
p \frac{\partial f(\mathbf{x})}{\partial x_i} = \omega_i 
\]
we call $p \frac{\partial f(\mathbf{x})}{\partial x_i}$ the Marginal Revenue Product of input $i$, which the FOC says that it must be equal to the price of input $i$. Using this method, we should see that we will get the optimal profit and such. 
\subsection{Optimal Scale}
During the second step of the cost minimization process, we see that we can write it as 
\[
\max_y py - c(\mathbf{\omega}, y)
\]
The FOC for an interior solution requires that 
\[
p = \frac{\partial c(\omega, y)}{\partial y}
\]
where marginal revenue equals to the marginal cost. But the SOC requires that 
\[
\frac{\partial^2 c(\omega, y)}{\partial y^2} \geq 0 
\]
where producing more $y$ means costs go up. However, note there are some cases where, we can have the exogenously given variables dictating everything. See his slides 
\section{Competitive Equilbirum}
Weeks 3,4,5
\section{Imperfect Equilbrium}
Week 6
\section{Intro to Game Theory}
Week 7, 8
\section{Imperfect Information}
Week 9


\end{document}