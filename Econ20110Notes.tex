\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{hyperref} 
\usepackage{amsmath}
\usepackage{ gensymb }
\usepackage{ amssymb }
\usepackage{float}
\usepackage{amsthm}
\usepackage{float}


\newcommand{\st}{\text{s.t}}


\title{Econ 20110 Notes}
\author{Anthony Yoon}
\date{January 2025}
\begin{document}
\maketitle
\tableofcontents
\section{Production Theory}
Weeks 1 and 2\\
In economics, we are concerned about constrained optimization, where we see that we want to optimize a parameter given some constraints. In Econ 20010, we were mainly concerned about the two good case, $x_1. x_2$, but now we are concerned about vectors, which are general collections of objects. In this case, we can be concerned about vectors, denoted by \textbf{bold} letters, like $\mathbf{x}$, essentially are any amount of goods that we are interested in. These problems present themselves in the form 
\begin{align*}
    \max_{\mathbf{X}} & \quad U(\mathbf{x})\\
    \st & \quad \mathbf{p} \cdot \mathbf{x} \leq m
\end{align*}
We can see that generally speaking, we have an objective function (the utility function), and choice vectors ($\mathbf{x}$). But we can also introduce the notion of paramter vectors, denoted as $\theta$. In [ump], these were prices and the budget and in the [emp], these where denoted as prices and utility. Now when we solve these equations, we see that we were able to derive a solution function, usually the Marshallian or the Hicksian demand functions. But we can generalize these kind of functions to that of solution functions, which are functions that . One thing we can note is that whenever we solve an optimization problem, we are not only solving for the solution function, we are solving for whole class of functions that allow us to see behavior as parameters change etc. Hence, we can find the following:
\begin{itemize}
    \item \textbf{Solution Function}: Optimal solution as a function of $\theta$. Ex. Marshallian and Hicksian
    \item \textbf{Value Function}: What is the optimized value as a function of $\theta$. Ex. Indirect Utility function, Expenditure Function
    \item \textbf{Envelope Theroem}: We can use this to link the value function to the solution function
\end{itemize}
\subsection{Kuhn Tucker Theroem}
Up to this point, we have assumed that everything is nice within optimization problems, where in the first order condtions, we can see that for $i \in I$ where $I$ is an indexing set
\[
\frac{\partial L}{\partial x_i} = \frac{\partial U}{\partial x_i} - \lambda p_i = 0
\]
but from now on, we cannot assume that as that is not representive of the real world. Instead, we have to consider first order conditions such that
\[
\frac{\partial L}{\partial x_i} =  \frac{\partial U}{\partial x_i} - \lambda p_i \leq 0 \quad x_i \geq 0
\] 
\[
\frac{\partial L}{\partial \lambda} = m - \sum_{x=1}^I p_i x_i \geq 0 \quad \lambda \geq 0 
\]
where we introduce complementary slackness into each condition. Before we discuss what this means, we can introduce the idea of \emph{interior solutions}. When we do this, consider an interval $[a,b]$. Let $c \in [a,b]$. If $f'(c) = 0$, then it is a optimzer, but we can also consider the endpoints, $a,b$. If the endpoints contain the maximum/minimum value, we can see that there are actually the minimizer and maximumizer values themselves, but the values of the first order conditions can be positive or negative. Hence, we introduce complemntary slackness. We can consider $x_i \in [0, \infty)$ as denoted by the restriction. If $x_1 \in (0,\infty)$ then the first order condition must be strict equality. If $x_1 = 0$, then we know that the first order condition can include the case where the deriative may be negative. Note that these statements are if and only if statements. 
\section{Competitive Equilbirum}
Weeks 3,4,5
\section{Imperfect Equilbrium}
Week 6
\section{Intro to Game Theory}
Week 7, 8
\section{Imperfect Information}
Week 9


\end{document}